{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afraid-vegetarian",
   "metadata": {},
   "source": [
    "#### From Pieter Abbeel's Lectures\n",
    "\n",
    "##### Evaluating KL Divergence\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "KL(P(\\tau; \\theta) || P(\\tau; \\theta + \\delta \\theta)) &= \\sum_{\\tau} P(\\tau; \\theta) \\log \\dfrac{P(\\tau; \\theta)}{P(\\tau; \\theta + \\delta \\delta)} \\\\\n",
    "&= \\sum_{\\tau} P(\\tau; \\theta) \\log \\dfrac{\\sum_{t=0}^{H-1} \\pi_{\\theta} (a_t | s_t)}{\\sum_{t=0}^{H-1} \\pi_{\\theta + \\delta \\theta} (a_t | s_t)} \\\\\n",
    "& \\approx \\frac{1}{M} \\sum_{\\text{rollouts under }\\theta} \\log  \\dfrac{\\sum_{t=0}^{H-1} \\pi_{\\theta} (a_t | s_t)}{\\sum_{t=0}^{H-1} \\pi_{\\theta + \\delta \\theta} (a_t | s_t)}\\\\\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "Since dynamics cancels, and when we have expectation, we can use rollouts to estimate via Monte Carlo method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-flour",
   "metadata": {},
   "source": [
    "#### \"Flat Tangent\"\n",
    "\n",
    "$KL(\\pi_{\\theta}(a|s) ||\\pi_{\\theta + \\delta \\theta}(a|s)) \\approx \\delta \\theta^T \\big( \\sum_{(a,s) \\sim \\theta} \\nabla_{\\theta} \\log \\pi_{\\theta}(a|s) \\nabla_{\\theta} \\log \\pi_{\\theta}(a|s)^T \\big) \\delta \\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-correction",
   "metadata": {},
   "source": [
    "#### Studying\n",
    "\n",
    "* Studying from https://www.telesens.co/2018/06/09/efficiently-computing-the-fisher-vector-product-in-trpo/\n",
    "\n",
    "* The problem is that SGD offers no principled way to choose the right step size\n",
    "* If the step size is too big, the optimization may miss the minimum\n",
    "* If the step is too small, progress may be very slow\n",
    "* Standard machine learning methods address this problem by using automatic learning rate adjustment such as the Adam optimizer\n",
    "\n",
    "* TRPO reframes the optimization problem as a constrained optimization whose solution is guaranteed to result in an improved policy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-lounge",
   "metadata": {},
   "source": [
    "#### The Problem\n",
    "\n",
    "* The constrained optimization problem in TRPO\n",
    "\n",
    "$\\pi_{k+1} = argmax_{\\pi} L(\\pi)$\n",
    "\n",
    "such that\n",
    "\n",
    "$D_{KL}(\\pi, \\pi_{k}) \\le \\delta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-spending",
   "metadata": {},
   "source": [
    "Here, $D_{KL}(\\pi, \\pi_{k})$ is defined as\n",
    "\n",
    "$D_{KL}(\\pi, \\pi_{k}) = \\sum (\\pi_{k}) \\log \\dfrac{\\pi_{k}}{\\pi}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-wagon",
   "metadata": {},
   "source": [
    "$\\pi_{k}$ refers to the output of the network at the $k^{th}$ iteration with parameters $\\pi_{k}$. Since $\\theta_{k}$ is fixed, the only variable in the formula is $\\pi$\n",
    "\n",
    "Therefore, when calculating derivatives using autograd, we must detach $\\pi_{k}$ from the computation graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-strip",
   "metadata": {},
   "source": [
    "#### Numerical Optimization\n",
    "\n",
    "We use some numerical optimization techniques on (a) the loss function and (b) the constraint, specifically making Taylor series approximations to the functions\n",
    "\n",
    "$L_{\\theta_{k}}(\\theta) = L_{\\pi_{k}}(\\pi) \\sim L_{\\theta_{k}}(\\theta) + g^T (\\theta - \\theta_{k})$\n",
    "\n",
    "$D_{KL}(\\pi_{\\theta_{k}}, \\pi_{\\theta}) = D_{KL}(\\pi_{\\theta_{k}},\\pi_{\\theta_{k}}) + \\nabla_{\\theta} D_{KL}(\\pi_{\\theta_{k}}, \\pi_{\\theta}) (\\theta - \\theta_{k}) + \\frac{1}{2} (\\theta - \\theta_{k})^T H (\\theta - \\theta_{k})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-export",
   "metadata": {},
   "source": [
    "Our optimization problem reduces to \n",
    "\n",
    "$\\theta_{k+1} = argmax_{\\theta} g^T (\\theta - \\theta_{k})$\n",
    "\n",
    "such that\n",
    "\n",
    "$\\frac{1}{2} (\\theta - \\theta_{k})^T H (\\theta - \\theta_{k}) \\le \\delta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-oracle",
   "metadata": {},
   "source": [
    "As shown in the appendix of the TRPO paper, this problem is solved in two steps--\n",
    "\n",
    "1. A search direction for $\\theta$ is computed \n",
    "2. A maximum distance along this direction is calculated such that the constraint is still satisfied\n",
    "\n",
    "(1), the direction, can be calculated by applying the Lagrange multiplier technique.\n",
    "\n",
    "Let $s = (\\theta - \\theta_{k})$. Then the Lagrangian is given by\n",
    "\n",
    "$G = g^T s - \\lambda \\frac{1}{2} s^T H s$\n",
    "\n",
    "Differentiation wrt $s$ (giving us our direction!) and setting to $0$, we get\n",
    "\n",
    "$\\frac{\\partial G}{\\partial s} = g - \\lambda H s = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-cassette",
   "metadata": {},
   "source": [
    "The direction to search along is given by solving $Hs = g$. Now we must determine how far to move along this direction such that the constraint is still satisfied. Let this distance be denoted by $\\beta$.\n",
    "\n",
    "Thus, $\\theta = \\theta_{k} + \\beta s$\n",
    "\n",
    "Substituting this in the expression for the KL constraint, we get $\\beta s^T H \\beta s = \\delta$, thus\n",
    "\n",
    "$\\beta = \\sqrt{(\\dfrac{2 \\delta}{s^T H \\beta s})}$\n",
    "\n",
    "The product of $\\beta$ and $s$ gives the optimal step to update $\\theta$. This is the major contribution of TRPO, over ad hoc \"learning rate schedule\" typically used in training NNs.\n",
    "\n",
    "1. Compute search direction by solving $Hs = g$\n",
    "2. Maximum step size is computed using formula for $\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-belief",
   "metadata": {},
   "source": [
    "Note that we are interested in the matrix-vector product $H^{-1}g$, not the matrix $H^{-1}$ by itself.\n",
    "\n",
    "However calculating the Hessian matrix itself is a problem for autograd because its automatic differentiation feature is designed to calculate the derivative of a scalar wrt a vector, whereas the Hessian matrix involves the derivative of a vector (the derivative of the loss wrt the policy parameters) wrt a vector (policy parameters). One could of course loop over each element of the vector (code shown below), however this would be very slow, and require a lot of storage to store a K \\times K Hessian matrix where K is a large number (in the thousands)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-lindsay",
   "metadata": {},
   "source": [
    "#### A Math Trick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-specification",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "$H_{ij} = \\dfrac{\\partial}{\\partial \\theta_{j}} \\dfrac{\\partial D_{KL}}{\\partial \\theta_{i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-miniature",
   "metadata": {},
   "source": [
    "The $k^{th}$ element of the matrix vector product $Hx$ is:\n",
    "\n",
    "$ \\begin{align*}\n",
    "y_{k} &= \\sum_{j} H_{kj} x_{j} \\\\\n",
    "&= \\sum_{j} \\dfrac{\\partial}{\\partial \\theta_{j}} \\dfrac{\\partial D_{KL}}{\\partial \\theta_{k}} x_j \\\\\n",
    "&= \\dfrac{\\partial}{\\partial \\theta_{k}} \\sum_{j}  \\dfrac{\\partial D_{KL}}{\\partial \\theta_{k}} x_j  \\\\\n",
    "\\end{align*} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-lover",
   "metadata": {},
   "source": [
    "The full vector is\n",
    "\n",
    "$y = \\dfrac{\\partial}{\\partial \\theta} \\sum_{j}  \\dfrac{\\partial D_{KL}}{\\partial \\theta_{k}} x_j $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-intake",
   "metadata": {},
   "source": [
    "Thus, the matrix-vector product can be calculated by first calculating the first derivative of the KL distance wrt the network params, and the product of this derivative vector with the input vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-sampling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
