# Policy Gradient Methods

Added ipython notebook to walk through the derivation and implementation of vanilla policy gradient, derivation of TRPO. Beginning implementation of PPO.
