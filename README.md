# Policy Gradient Methods

Added ipython notebook to walk through the derivation and implementation of vanilla policy gradient, derivation of TRPO. Added derivation and implementation of PPO. Beginning notes and code implementation for DDPG.

The contents of the notebook can now be found in a blog post [here](https://annhe.xyz/2021/04/12/policy-gradients/)

* 06-22-21 Update: Starting implementation of TRPO
* 06-22-21 To-Do: Read Fisher information matrix = Hessian of KL divergence, decide how to compute sample H
* 06-25-21 Update: Added notes folder and notes on KL divergence
