# vpg

Added ipython notebook to walk through the derivation and implementation of vanilla policy gradient.
