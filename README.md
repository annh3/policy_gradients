# Policy Gradient Methods

Added ipython notebook to walk through the derivation and implementation of vanilla policy gradient, derivation of TRPO. Added derivation and implementation of PPO.
