# Policy Gradient Methods

Added ipython notebook to walk through the derivation and implementation of vanilla policy gradient, derivation of TRPO. Added derivation and implementation of PPO.

The contents of the notebook can now be found in a blog post [here](https://annhe.xyz/2021/04/12/policy-gradients/)
